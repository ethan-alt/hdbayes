---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

library(hdbayes)
library(rstan)
```

## hdbayes

<!-- badges: start -->
[![R-CMD-check](https://github.com/ethan-alt/hdbayes/workflows/R-CMD-check/badge.svg)](https://github.com/ethan-alt/hdbayes/actions)
<!-- badges: end -->

The goal of `hdbayes` is to make it easier for users to conduct Bayesian analysis
methods that leverage historical data.


## Setting up MCMC parameters
We begin by setting up parameters for the MCMC. We detect the number of cores
on our machine as well as set up the warmup and total number of desired
samples.
```{r parallel_setup}
## obtain number of cores
ncores = max(1, parallel::detectCores() - 1)
warmup  = 1000          ## warmup for MCMC sampling
total.samples = 10000   ## number of samples post warmup
samples = ceiling(warmup + total.samples / ncores)  ## outputs approx total.samples samples
```


## Simulating logistic regression data
We now simulate some logistic regression data.
```{r simdata}
## simulate logistic regression data
set.seed(391)
n  = 200
n0 = 100
N  = n + n0

X    = cbind(1, 'z' = rbinom(N, 1, 0.5), 'x' = rnorm(N, mean = 1, sd = 1) )
beta = c(1, 0.5, -1)
mean = binomial('logit')$linkinv(X %*% beta)
y    = rbinom(N, 1, mean)

## create current and historical data sets
data = data.frame('y' = y, 'z' = X[, 'z'], 'x' = X[, 'x'])
histdata = data[1:n0, ]
data     = data[-(1:n0), ]
```


## Frequentist analysis of the data sets
We use the `stats::glm` function to conduct a frequentist GLM of the data sets
```{r freq_glm}
formula = y ~ z + x
family  = binomial('logit')
fit.mle.cur  = glm(formula, family, data)
fit.mle.hist = glm(formula, family, histdata)

summary(fit.mle.cur)
```

We will compare these with the Bayesian analysis results later

## Bayesian analysis methods
We now utilize the functions in this package.

### Bayesian hierarchical model
The Bayesian hierarchical model (BHM) is the following model:
$$
\begin{align*}
  y_i | x_i, \beta &\sim \text{Bernoulli}\left( \text{logit}^{-1}(x_i'\beta) \right) \\
  y_{0i} | x_{0i}, \beta_0 &\sim \text{Bernoulli}\left( \text{logit}^{-1}(x_{0i}'\beta_0) \right) \\
  \beta, \beta_0 &\sim N_p(\mu, \Sigma) \\
  \mu &\sim N_p(\mu_0, \Sigma_0) \\
  \Sigma &\sim \text{IW}_p(\nu_0, \Psi_0)
\end{align*}
$$
where $\beta$ is the vector of regression coefficients of the current data
set, $\beta_0$ is the vector of regression coefficients for the historical
data set, $\mu$ is the common prior mean of $\beta$ and $\beta_0$, which is
treated as random with a normal hyperprior having mean $\mu_0$, and covariance
$\Sigma_0$, and $\Sigma$ is also treated as random, having an inverse-Wishart
hyperprior with $\nu_0$ degrees of freedom and scale matrix $\Psi_0$. 

The defaults in `hdbayes` are

* $\mu_0 = 0$
* $\Sigma_0 = I_p$
* $\nu_0 = p + 10$
* $\Psi_0 = I_p$
where $p$ is the number of predictors (including the intercept if applicable).

We fit this model as follows
```{r bhm, echo = FALSE}
## Bayesian Hierarchical Model
fit.bhm = glm.bhm(
  formula, family, data, histdata,
  cores = ncores, chains = ncores, iter = samples, warmup = warmup, refresh = 0
)
summary(fit.bhm)$summary
```

### Commensurate prior
The commensurate prior assumes the following hierarchical model
$$
\begin{align*}
  y_i | x_i, \beta &\sim \text{Bernoulli}\left( \text{logit}^{-1}(x_i'\beta) \right) \\
  y_{0i} | x_{0i}, \beta_0 &\sim \text{Bernoulli}\left( \text{logit}^{-1}(x_{0i}'\beta_0) \right) \\
  \beta_0 &\sim N_p(\mu_0, \Sigma_0) \\
  \beta_j &\sim N_1\left( \beta_{0j}, \tau_j^{-1} \right), j = 1, \ldots, p
\end{align*}
$$
where the $\tau_j$'s are elicited by the user. The defaults in `hdbayes` are

* $\mu_0 = 0$
* $\Sigma_0 = 100 \times I_p$

This method can be fit as follows
```{r commensurate}
fit.commensurate = glm.commensurate(
  formula, family, data, histdata, tau = rep(5, 3),
  cores = ncores, chains = ncores, iter = samples, warmup = warmup, refresh = 0
)
summary(fit.commensurate)$summary
```


### Robust Meta-Analytic Predictive (MAP) Prior
The Robust MAP prior is a generalization of the Bayesian Hierarchical Model
(BHM), and takes the form

$$
\begin{align*}
  y_i | x_i, \beta &\sim \text{Bernoulli}\left( \text{logit}^{-1}(x_i'\beta) \right) \\
  y_{0i} | x_{0i}, \beta_0 &\sim \text{Bernoulli}\left( \text{logit}^{-1}(x_{0i}'\beta_0) \right) \\
  \beta_0 &\sim N_p(\mu, \Sigma) \\
  \beta   &\sim w \times N_p(\mu, \Sigma) + (1 - w) N_p(\mu_v, \Sigma_v) \\
  \mu &\sim N_p(\mu_0, \Sigma_0) \\
  \Sigma &\sim \text{IW}_p(\nu_0, \Psi_0)
\end{align*}
$$

where $w \in (0,1)$ controls for the level of borrowing of the historical data.
Note that when $w = 1$, the robust MAP prior effectively becomes the BHM. The
defaults are the same as in the BHM except the default value for w is 0.1.
```{r robustmap}
fit.robustmap = glm.robustmap(
  formula, family, data, histdata,
  cores = ncores, chains = ncores, iter = samples, warmup = warmup, refresh = 0
)
summary(fit.robustmap)$summary
```



### Power prior
The Power Prior takes the form
$$
\begin{align}
  y_i | x_i, \beta &\sim \text{Bernoulli}\left( \text{logit}^{-1}(x_i'\beta) \right) \\
  y_{0i} | x_{0i}, \beta &\sim \text{Bernoulli}\left( \text{logit}^{-1}(x_{0i}'\beta) \right) \\
  \pi(\beta | a_0) &\propto L(\beta | y_0)^{a_0} \pi_0(\beta)
\end{align}
$$
where $L(\beta | y_0)$ is the likelihood of the GLM based on the historical data,
$a_0 \in (0,1)$ is a fixed hyperaparameter controlling the effective
sample size contributed by the data (e.g., $a_0 = 1$ borrows the whole sample size),
and $\pi_0(\beta)$ is an "initial prior" on $\beta$.

The default in `hdbayes` is a (noninformative) normal prior on $\beta$:
$$
\beta \sim N_p(0, 100 \times I_p)
$$

The power prior (with $a_0 = 0.5$) may be fit as follows:
```{r powerprior}
fit.pp = glm.pp(
  formula, family, data, histdata, a0 = 0.5,
  cores = ncores, chains = ncores, iter = samples, warmup = warmup, refresh = 0
)
```



### Normalized power prior (NPP)
The NPP treats the hyperparameter $a_0$ as random, allowing the data to decide
what is the best value. For non-Gaussian models, this requires estimating
the normalizing constant 
$Z(a_0) = \int L(\beta | y_0)^{a_0} \pi_0(\beta) d\beta$. 

In `hdbayes`, there is one function to estimate the normalizing constant across
a grid of values for $a_0$ and another to obtain posterior samples of the
normalized power prior.

The NPP may be summarized as
$$
\begin{align}
  y_i | x_i, \beta &\sim \text{Bernoulli}\left( \text{logit}^{-1}(x_i'\beta) \right) \\
  y_{0i} | x_{0i}, \beta &\sim \text{Bernoulli}\left( \text{logit}^{-1}(x_{0i}'\beta) \right) \\
  \pi(\beta | a_0) &\propto \frac{1}{Z(a_0)} L(\beta | y_0)^{a_0} \pi_0(\beta) \\
  \pi(a_0)         &\propto a_0^{\alpha_0 - 1} (1 - a_0)^{\gamma_0 - 1}
\end{align}
$$

The defaults in `hdbayes` are

* $\pi_0(\beta) \propto N(\beta | 0, 100 \times I_p)$
* $\alpha_0 = 1$
* $\gamma_0 = 1$

when $\alpha_0 = 1$ and $\gamma_0 = 1$, the prior on $a_0$ is a $U(0,1)$ 
prior.

### Estimating the normalizing constant
We begin by estimating the normalizing constant over a fine grid of values.
On machines with multiple cores, this may be accomplished more efficiently
using parallel computing.

```{r npp_lognc}
## parallelize estimation of log normalizing constant
library(parallel)
a0     = seq(0, 1, length.out = ncores * 5)

## wrapper to obtain log normalizing constant in parallel package
logncfun = function(a0, ...)
  hdbayes::glm.npp.lognc(
    formula = formula, family = family, histdata = histdata, a0 = a0, ...
  )

cl = makeCluster(ncores)
  clusterSetRNGStream(cl, 123)
  clusterExport(cl, varlist = c('formula', 'family', 'histdata'))
  
  ## call created function
  a0.lognc = parLapply(
    cl = cl, X = a0, fun = logncfun, iter = 5000, warmup = warmup, refresh = 0
  )
stopCluster(cl)

a0.lognc = data.frame( do.call(rbind, a0.lognc) )
head(a0.lognc)
```

The provided function `glm.npp.lognc` estimates the logarithm of the
normalizing constant, $\log Z(a_0)$, for one specific value of $a_0$. We 
created the function `logncfun` so that the first argument would be $a_0$,
allowing us to use the `parLapply` function in the `parallel` package.

The `hdbayes` function `glm.npp.lognc` outputs $a_0$, $Z(a_0)$, and the
minimum effective sample size and maximum R-hat value of the MCMC sampling
of the power prior. It is a good idea to check that the minimum
effective sample size is at least 1,000 and the maximum R-hat value is 
less than 1.10

```{r npp_lognc_2}
min(a0.lognc$min_n_eff) ## lowest effective sample size
max(a0.lognc$max_Rhat)  ## highest R-hat value
```

We can then plot the logarithm of the normalizing constant
```{r npp_lognc_plot}
plot(a0.lognc$a0, a0.lognc$lognc)
```


### Sampling the posterior distribution
We can now sample from the posterior distribution. The function
`glm.npp` takes, as input, values of $a_0$ and the estimated logarithm
of the normalizing constant. Linear interpolation is used to estimate 
$Z(a_0)$ for values not in the fine grid. Thus, it may be a good idea to
conduct smoothing of the function such as using LOESS, but we ignore that here.


```{r npp_sample}
fit.npp = glm.npp(
  formula, family, data, histdata, a0 = a0.lognc$a0, lognc = a0.lognc$lognc,
  cores = ncores, chains = ncores, iter = samples, warmup = warmup, refresh = 0
)
summary(fit.npp)$summary
```





### Normalized asymptotic power prior (NAPP)
NAPP uses a large sample theory argument to formulate a normal approximation
to the power prior, i.e., the prior is given by
$$
\beta | a_0 \sim N(\hat{\beta}_0, a_0^{-1} [I_n(\beta)]^{-1}),
$$
where $\hat{\beta}_0$ is the maximum likelihood estimate (MLE) of $\beta$
based on the historical data and $I_n(\beta)$ is the associated information
matrix (negative Hessian).

In this case, the normalizing constant is known, so we do not need to estimate
the normalizing constant before sampling. 

The following code analyzes the data set using the NAPP:
```{r napp}
fit.napp = glm.napp(
  formula, family, data, histdata,
  cores = ncores, chains = ncores, iter = samples, warmup = warmup, refresh = 0
)
summary(fit.napp)$summary
```



## Comparison of methods
We now can compare the point estimate (MLE / posterior mean) and uncertainty
(SE / posterior standard deviation) of the methods.

```{r comparison}
##
## COMPARE METHODS
##
fit.list = list('bhm' = fit.bhm, 'commensurate' = fit.commensurate,
                'robustmap' = fit.robustmap, 'napp' = fit.napp,
                'npp' = fit.npp, 'pp' = fit.pp)

post.mean = sapply(
  fit.list, function(x) summary(x)$summary[names(coef(fit.mle.cur)), 'mean']
)
post.sd = sapply(
  fit.list, function(x) summary(x)$summary[names(coef(fit.mle.cur)), 'sd']
)

post.mean = cbind(
  'truth' = beta,
  'mle.cur' = coef(fit.mle.cur),
  'mle.hist' = coef(fit.mle.hist),
  post.mean
)

post.sd = cbind(
  'mle.cur'  = summary(fit.mle.cur)$coefficients[, 'Std. Error'],
  'mle.hist' = summary(fit.mle.hist)$coefficients[, 'Std. Error'],
  post.sd
)

## posterior means
post.mean

## posterior std dev.
post.sd
```



